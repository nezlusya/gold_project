import logging
import duckdb
import pendulum
from airflow import DAG
from airflow.models import Variable
from airflow.operators.empty import EmptyOperator
from airflow.operators.python import PythonOperator
from airflow.sensors.external_task import ExternalTaskSensor


# --- –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ---
OWNER = "Luda"
DAG_ID = "from_minio_to_pg_6"

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ü–µ–ª–∏
LAYER = "raw"
SOURCE = "gold_price_cbr"
SCHEMA = "ods"
TARGET_TABLE = "gold_price_cbr_6"

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ Airflow Variables
ACCESS_KEY = Variable.get("access_key", default_var="minioadmin")
SECRET_KEY = Variable.get("secret_key", default_var="minioadmin")
PASSWORD = Variable.get("pg_password", default_var="postgres")

# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
LONG_DESCRIPTION = """
# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–∞—Ö –Ω–∞ –∑–æ–ª–æ—Ç–æ –∏–∑ MinIO –≤ PostgreSQL
- –ò—Å—Ç–æ—á–Ω–∏–∫: s3://prod/raw/gold_price_cbr/YYYY-MM-DD/data.parquet
- –¶–µ–ª—å: —Ç–∞–±–ª–∏—Ü–∞ ods.gold_price_cbr
"""

SHORT_DESCRIPTION = "–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –∑–æ–ª–æ—Ç–∞ –∏–∑ MinIO (RAW) –≤ PostgreSQL (ODS)"

args = {
    "owner": OWNER,
    "start_date": pendulum.datetime(2025, 4, 5, tz="Europe/Moscow"),
    "catchup": True,
    "retries": 3,
    "retry_delay": pendulum.duration(minutes=30),
}


def get_dates(**context):
    start_date = context["data_interval_start"].format("YYYY-MM-DD")
    end_date = context["data_interval_end"].format("YYYY-MM-DD")
    return start_date, end_date


def transfer_to_pg(**context):
    start_date, end_date = get_dates(**context)
    logging.info(f"üíª Start transfer for date: {start_date}")

    con = duckdb.connect()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MinIO –∏ PostgreSQL
    con.sql(f"""
        SET TIMEZONE='UTC';
        LOAD httpfs;
        SET s3_url_style = 'path';
        SET s3_endpoint = 'minio:9000';
        SET s3_access_key_id = '{ACCESS_KEY}';
        SET s3_secret_access_key = '{SECRET_KEY}';
        SET s3_use_ssl = FALSE;

        CREATE SECRET dwh_postgres (
            TYPE postgres,
            HOST 'postgres_dwh',
            PORT 5432,
            DATABASE postgres,
            USER 'gold_user',
            PASSWORD '{PASSWORD}'
        );

        ATTACH '' AS dwh_postgres_db (TYPE postgres, SECRET dwh_postgres);
    """)

    try:
        # 1Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ –¥–∞—Ç—É –∏–∑ MinIO
        con.sql(f"""
            CREATE OR REPLACE TEMP TABLE new_data AS
            SELECT * 
            FROM 's3://prod/{LAYER}/{SOURCE}/{start_date}/data.parquet';
        """)

        # 2Ô∏è‚É£ –£–¥–∞–ª—è–µ–º –∏–∑ PostgreSQL –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ 6 –º–µ—Å—è—Ü–µ–≤
        con.sql(f"""
            DELETE FROM dwh_postgres_db.{SCHEMA}.{TARGET_TABLE}
            WHERE date < (CURRENT_DATE - INTERVAL '6 months');
        """)

        # 3Ô∏è‚É£ –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ)
        con.sql(f"""
            INSERT INTO dwh_postgres_db.{SCHEMA}.{TARGET_TABLE} (date, buy_price, sell_price)
            SELECT date, buy_price, sell_price
            FROM new_data
            WHERE date >= (CURRENT_DATE - INTERVAL '6 months');
        """)

        logging.info(f"‚úÖ Transfer success for date: {start_date}")

    except duckdb.duckdb.HTTPException:
        logging.warning(f"‚ö†Ô∏è File for {start_date} not found in MinIO")
    finally:
        con.close()


# --- DAG ---
with DAG(
    dag_id=DAG_ID,
    schedule_interval="0 5 * * *",  # –ø–æ—Å–ª–µ –≤—ã–≥—Ä—É–∑–∫–∏ from_api_to_s3 (—á–µ—Ä–µ–∑ —á–∞—Å)
    default_args=args,
    tags=["s3", "ods", "pg"],
    description=SHORT_DESCRIPTION,
    concurrency=1,
    max_active_tasks=1,
    max_active_runs=1,
) as dag:
    dag.doc_md = LONG_DESCRIPTION

    start = EmptyOperator(task_id="start")

    wait_for_raw_layer = ExternalTaskSensor(
        task_id="wait_for_raw_layer",
        external_dag_id="from_api_to_s3",  # –∂–¥–µ–º DAG, –∫–æ—Ç–æ—Ä—ã–π –≥—Ä—É–∑–∏—Ç –≤ MinIO
        allowed_states=["success"],
        mode="reschedule",
        timeout=36000,
        poke_interval=60,
    )

    transfer_to_pg = PythonOperator(
        task_id="transfer_to_pg",
        python_callable=transfer_to_pg,
    )

    end = EmptyOperator(task_id="end")
    start >> wait_for_raw_layer >> transfer_to_pg >> end
